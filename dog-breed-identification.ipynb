{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1e2d8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5132b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a72fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddfc36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dog-breed-identification/\"\n",
    "train_path = os.path.join(path, \"train/*\")\n",
    "test_path = os.path.join(path, \"test/*\")\n",
    "labels_path = os.path.join(path, \"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda6e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(labels_path)\n",
    "# labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01fd7f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed = labels_df[\"breed\"].unique()\n",
    "# breed\n",
    "len(breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e98c5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "breed2id = {name: i for i, name in enumerate(breed)}\n",
    "id2breed = {i: name for i, name in enumerate(breed)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40deb1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = glob(train_path)\n",
    "# ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a030765",
   "metadata": {},
   "outputs": [],
   "source": [
    "lables = []\n",
    "for image_id in ids:\n",
    "    image_id = image_id.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    # print(image_id)\n",
    "    breed_name = list(labels_df[labels_df.id == image_id][\"breed\"])[0]\n",
    "    # print(image_id, breed_name)\n",
    "    breed_idx = breed2id[breed_name]\n",
    "    lables.append(breed_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35cacaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x = train_test_split(ids, test_size=0.33, random_state=42)\n",
    "train_y, valid_y = train_test_split(lables, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c122d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "size = 224\n",
    "num_classes = 120\n",
    "lr = 1e-4\n",
    "batch = 16\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "208c157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(input_shape=(224,224,3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73b8fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8cc45116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9ec7ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=Adam(learning_rate=lr), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a7d7303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1311744   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 120)               123000    \n",
      "=================================================================\n",
      "Total params: 3,692,728\n",
      "Trainable params: 1,434,744\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2889ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, size):\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (224,224))\n",
    "    image = image/255.0\n",
    "    image = image.astype(np.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d41691cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(x,y):\n",
    "    x = x.decode()\n",
    "    num_classes = 120\n",
    "    size = 224\n",
    "    image =read_image(x,size)\n",
    "    label = [0] * num_classes\n",
    "    label[y] = 1\n",
    "    label = np.array(label)\n",
    "    label = label.astype(np.int32)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "beb7092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_parse(x,y):\n",
    "    x,y = tf.numpy_function(parse_data, [x,y], [tf.float32, tf.int32])\n",
    "    x.set_shape((224,224,3))\n",
    "    y.set_shape((120))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df4f6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(x, y, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f89b35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "train_dataset = tf_dataset(train_x, train_y, batch=batch)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3d9059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in valid_dataset:\n",
    "#     print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "efeadab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"model.h5\", verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "train_steps = (len(train_x)//batch) + 1\n",
    "valid_steps = (len(valid_x)//batch) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a589e9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "429/429 [==============================] - 28s 65ms/step - loss: 0.7482 - accuracy: 0.7912 - val_loss: 1.3249 - val_accuracy: 0.6108\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.32490, saving model to model.h5\n",
      "Epoch 2/10\n",
      "  1/429 [..............................] - ETA: 13s - loss: 0.6840 - accuracy: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mehul\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/429 [==============================] - 28s 66ms/step - loss: 0.6288 - accuracy: 0.8341 - val_loss: 1.3283 - val_accuracy: 0.6194\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.32490\n",
      "Epoch 3/10\n",
      "429/429 [==============================] - 28s 66ms/step - loss: 0.5383 - accuracy: 0.8601 - val_loss: 1.3365 - val_accuracy: 0.6165\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.32490\n",
      "Epoch 4/10\n",
      "429/429 [==============================] - 29s 67ms/step - loss: 0.4625 - accuracy: 0.8830 - val_loss: 1.3445 - val_accuracy: 0.6203\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.32490\n",
      "Epoch 5/10\n",
      "429/429 [==============================] - 29s 67ms/step - loss: 0.4031 - accuracy: 0.9027 - val_loss: 1.3588 - val_accuracy: 0.6183\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.32490\n",
      "Epoch 6/10\n",
      "429/429 [==============================] - 29s 67ms/step - loss: 0.3483 - accuracy: 0.9229 - val_loss: 1.3548 - val_accuracy: 0.6286\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.32490\n",
      "Epoch 7/10\n",
      "429/429 [==============================] - 29s 67ms/step - loss: 0.2750 - accuracy: 0.9459 - val_loss: 1.2688 - val_accuracy: 0.6396\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.32490 to 1.26881, saving model to model.h5\n",
      "Epoch 8/10\n",
      "429/429 [==============================] - 29s 68ms/step - loss: 0.2520 - accuracy: 0.9528 - val_loss: 1.2675 - val_accuracy: 0.6414\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.26881 to 1.26749, saving model to model.h5\n",
      "Epoch 9/10\n",
      "429/429 [==============================] - 29s 68ms/step - loss: 0.2459 - accuracy: 0.9583 - val_loss: 1.2694 - val_accuracy: 0.6408\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.26749\n",
      "Epoch 10/10\n",
      "429/429 [==============================] - 29s 69ms/step - loss: 0.2434 - accuracy: 0.9594 - val_loss: 1.2709 - val_accuracy: 0.6343\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.26749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cce2887940>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, steps_per_epoch=train_steps, validation_data=valid_dataset,\n",
    "          validation_steps=valid_steps, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fae0be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d980f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b5932353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 14.17it/s]\n"
     ]
    }
   ],
   "source": [
    "for i,path in tqdm(enumerate(valid_x[:10])):\n",
    "    image = read_image(path, 224)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    pred = model_test.predict(image)[0]\n",
    "    label_idx = np.argmax(pred)\n",
    "    breed_name = id2breed[label_idx]\n",
    "    \n",
    "    ori_breed = id2breed[valid_y[i]]\n",
    "    ori_image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    ori_image = cv2.putText(ori_image, breed_name, (0,10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (225,0,0), 1)\n",
    "    ori_image = cv2.putText(ori_image, ori_breed, (0,30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,225,225), 1)\n",
    "    cv2.imwrite(f\"save/valid_{i}.png\", ori_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab6e2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
